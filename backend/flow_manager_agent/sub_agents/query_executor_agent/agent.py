from backend.bq import BQClient
from backend.flow_manager_agent.utils.cache import CacheService, normalize_intent_key
import pandas as pd
import logging
import json

logger = logging.getLogger(__name__) 


def run_bigquery(query: str):
    """Executes a BigQuery SQL query and returns results as markdown."""
    logger.info("=" * 80)
    logger.info("ğŸ”µ run_bigquery called")
    logger.info("SQL to execute:\n%s", query)
    logger.info("=" * 80)
    
    try:
        logger.info("ğŸ”µ Creating BQClient instance...")
        bq = BQClient()
        logger.info("âœ… BQClient created successfully")

        # Runner that returns list[dict] rows
        def _runner(sql: str):
            logger.info("ğŸ”µ _runner executing query...")
            it = bq.execute_query(sql, 'adk_query')
            logger.info("âœ… Query executed, converting to dataframe...")
            df = it.to_dataframe()
            logger.info(f"âœ… DataFrame created with {len(df)} rows")
            records = df.to_dict(orient='records')
            logger.info(f"âœ… Converted to {len(records)} records")
            return records

        logger.info("ğŸ”µ Creating CacheService...")
        cs = CacheService()
        intent_key = normalize_intent_key(sql=query)
        logger.info(f"ğŸ”µ Cache key: {intent_key}")
        
        logger.info("ğŸ”µ Running query with cache...")
        rows, from_cache = cs.run_query_with_cache(sql=query, intent_key=intent_key, run_bigquery_fn=_runner)
        logger.info(f"âœ… Query completed! Got {len(rows)} rows (from_cache={from_cache})")

        # Build markdown result for downstream agents
        logger.info("ğŸ”µ Building markdown output...")
        df_out = pd.DataFrame(rows)
        markdown = df_out.to_markdown(index=False) if not df_out.empty else ""
        logger.info(f"âœ… Markdown length: {len(markdown)} chars")
        logger.info(f"Markdown preview:\n{markdown[:500]}")

        result = {
            "status": "ok",
            "result": markdown,
            "message": None,
            "row_count": len(rows),
            "executed_sql": query,
            "from_cache": from_cache,
        }
        logger.info("âœ… run_bigquery completed successfully")
        logger.info("=" * 80)
        return result
        
    except Exception as e:
        logger.exception("âŒ BigQuery execution failed")
        error_result = {
            "status": "error",
            "result": None,
            "message": f"BigQuery execution error: {e}",
            "executed_sql": query,
        }
        logger.error(f"Error result: {error_result}")
        logger.info("=" * 80)
        return error_result


def query_executor_agent(previous_output: dict) -> dict:
    """
    Pure Python function that executes SQL query from the previous agent's output.
    
    Args:
        previous_output: JSON object from the previous agent, either:
            - { "built_query": {...} } or
            - { "status": "...", "sql": "...", ... } directly
    
    Returns:
        Result of the BigQuery execution
    """
    logger.info("ğŸŸ¢" * 40)
    logger.info("ğŸŸ¢ query_executor_agent (Python function) called")
    logger.info(f"ğŸŸ¢ Input type: {type(previous_output)}")
    logger.info(f"ğŸŸ¢ Input: {json.dumps(previous_output, indent=2) if isinstance(previous_output, dict) else previous_output}")
    
    try:
        # Parse input if it's a string
        if isinstance(previous_output, str):
            logger.info("ğŸŸ¢ Input is string, parsing JSON...")
            previous_output = json.loads(previous_output)
            logger.info("âœ… JSON parsed successfully")
        
        # Extract built_query
        if "built_query" in previous_output:
            logger.info("ğŸŸ¢ Found 'built_query' key, extracting...")
            built_query = previous_output["built_query"]
        else:
            logger.info("ğŸŸ¢ No 'built_query' key, using entire input as built_query")
            built_query = previous_output
        
        logger.info(f"ğŸŸ¢ built_query: {json.dumps(built_query, indent=2)}")
        
        # Check status
        status = built_query.get("status")
        logger.info(f"ğŸŸ¢ Status check: '{status}'")
        
        if status != "ok":
            logger.warning(f"âš ï¸ Status is not 'ok', returning error")
            return {
                "status": "error",
                "result": None,
                "message": "SQL cannot be executed because status is not ok."
            }
        
        # Extract and execute SQL
        sql = built_query.get("sql")
        logger.info(f"ğŸŸ¢ Extracted SQL: {sql[:100] if sql else 'None'}...")
        
        if not sql:
            logger.error("âŒ No SQL found in built_query")
            return {
                "status": "error",
                "result": None,
                "message": "No SQL found in built_query"
            }
        
        # Execute the query
        logger.info("ğŸŸ¢ Calling run_bigquery...")
        result = run_bigquery(sql)
        logger.info(f"âœ… run_bigquery returned: {json.dumps(result, indent=2)[:500]}...")
        logger.info("ğŸŸ¢" * 40)
        return result
        
    except Exception as e:
        logger.exception("âŒ query_executor_agent failed")
        error_result = {
            "status": "error",
            "result": None,
            "message": f"Query executor error: {e}"
        }
        logger.error(f"Error result: {error_result}")
        logger.info("ğŸŸ¢" * 40)
        return error_result
